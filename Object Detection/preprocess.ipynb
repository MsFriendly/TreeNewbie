{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/home/migo/Downloads/INF117/1027data'\n",
    "TAKE = '1027data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(f'./data/{TAKE}/annotations')\n",
    "# os.makedirs(f'./data/{TAKE}/imgs')\n",
    "os.makedirs(f'./data/{TAKE}/train')\n",
    "os.makedirs(f'./data/{TAKE}/test')\n",
    "os.makedirs(f'./data/{TAKE}/val')\n",
    "# shutil.copyfile(f'{PATH_TO_DATA}/{TAKE}.json', f'data/{TAKE}/annotations/{TAKE}.json')\n",
    "\n",
    "# for f in os.listdir(f'{PATH_TO_DATA}/imgs'):\n",
    "#     os.rename(f'{PATH_TO_DATA}/imgs/{f}', f'./data/{TAKE}/imgs/{f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/{TAKE}/annotations/{TAKE}.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "import random\n",
    "images_id_list = []\n",
    "for i in data['images']:\n",
    "  # print(i['id'])\n",
    "  images_id_list.append(i['id'])\n",
    "\n",
    "# print(len(images_id_list))\n",
    "train_set_ratio = 0.8\n",
    "splt_value = int(train_set_ratio*len(images_id_list))\n",
    "random.shuffle(images_id_list)\n",
    "train_data_id = images_id_list[:splt_value]\n",
    "test_val_data_id = images_id_list[splt_value:]\n",
    "val_set_ratio = 0.2 # 50% of the test+val images\n",
    "splt_value = int(train_set_ratio*len(test_val_data_id))\n",
    "random.shuffle(test_val_data_id)\n",
    "val_data_id = test_val_data_id[:splt_value]\n",
    "test_data_id = test_val_data_id[splt_value:]\n",
    "training_set_images = []\n",
    "val_set_images = []\n",
    "test_set_images = []\n",
    "for i in data['images']:\n",
    "    if i['id'] in train_data_id:\n",
    "        training_set_images.append(i)\n",
    "    elif i['id'] in val_data_id:\n",
    "        val_set_images.append(i)\n",
    "    else:\n",
    "        test_set_images.append(i)\n",
    "\n",
    "training_annotations = []\n",
    "val_annotations = []\n",
    "test_annotations = []\n",
    "for i in data['annotations']:\n",
    "    if i['image_id'] in train_data_id:\n",
    "        training_annotations.append(i)\n",
    "    elif i['image_id'] in val_data_id:\n",
    "        val_annotations.append(i)\n",
    "    else:\n",
    "        test_annotations.append(i)\n",
    "\n",
    "training_dataset = {}\n",
    "training_dataset['images'] = training_set_images\n",
    "training_dataset['annotations'] = training_annotations\n",
    "training_dataset['info'] = data['info']\n",
    "training_dataset['categories'] = data['categories']\n",
    "\n",
    "val_dataset = {}\n",
    "val_dataset['images'] = val_set_images\n",
    "val_dataset['annotations'] = val_annotations\n",
    "val_dataset['info'] = data['info']\n",
    "val_dataset['categories'] = data['categories']\n",
    "\n",
    "test_dataset = {}\n",
    "test_dataset['images'] = test_set_images\n",
    "test_dataset['annotations'] = test_annotations\n",
    "test_dataset['info'] = data['info']\n",
    "test_dataset['categories'] = data['categories']\n",
    "\n",
    "with open(f\"data/{TAKE}/annotations/ember_train_dataset.json\", \"w\") as file:\n",
    "    json.dump(training_dataset, file, indent=4)\n",
    "\n",
    "with open(f\"data/{TAKE}/annotations/ember_val_dataset.json\", \"w\") as file:\n",
    "    json.dump(val_dataset, file, indent=4)\n",
    "\n",
    "with open(f\"data/{TAKE}/annotations/ember_test_dataset.json\", \"w\") as file:\n",
    "    json.dump(test_dataset, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/{TAKE}/annotations/ember_train_dataset.json\", \"r\") as file:\n",
    "    data_train = json.load(file)\n",
    "\n",
    "for i in data_train[\"images\"]:\n",
    "    source = os.path.join(f\"data/{TAKE}/imgs/\", i[\"file_name\"])\n",
    "    shutil.copy(source, f\"data/{TAKE}/train\")\n",
    "\n",
    "with open(f\"data/{TAKE}/annotations/ember_val_dataset.json\", \"r\") as file:\n",
    "    data_val = json.load(file)\n",
    "\n",
    "for i in data_val[\"images\"]:\n",
    "    source = os.path.join(f\"data/{TAKE}/imgs/\", i[\"file_name\"])\n",
    "    shutil.copy(source, f\"data/{TAKE}/val\")\n",
    "\n",
    "with open(f\"data/{TAKE}/annotations/ember_test_dataset.json\", \"r\") as file:\n",
    "    data_test = json.load(file)\n",
    "\n",
    "for i in data_test[\"images\"]:\n",
    "    source = os.path.join(f\"data/{TAKE}/imgs/\", i[\"file_name\"])\n",
    "    shutil.copy(source, f\"data/{TAKE}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5336e623b002d26a1f558f113d43641ae3b5f9eedd6e0d06bd5a4d9e3d81c743"
  },
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "mmdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
